{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Проверка датасета"
      ],
      "metadata": {
        "id": "gFXilAoHyYam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate image dataset: existence, readability, and expected size\n",
        "# Works with: CSV (\"path,label\") or TXT lines \"path label\" (space/comma separated)\n",
        "\n",
        "import os, csv, sys, time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "from PIL import Image, ImageFile, UnidentifiedImageError\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = False  # raise on truncated files\n",
        "\n",
        "# ==== CONFIG ====\n",
        "INDEX_PATH   = \"/content/hirise-map-proj-v3/cleared_dataset.csv\"  # or dataset.csv\n",
        "ROOT_DIR     = \"/content/hirise-map-proj-v3/map-proj-v3/\"             # optional prefix for relative paths (\"\" = leave as-is)\n",
        "EXPECTED_W   = 227\n",
        "EXPECTED_H   = 227\n",
        "MAX_WORKERS  = max(2, os.cpu_count() or 2)\n",
        "LIST_EXAMPLES = 20            # how many sample bad files to print\n",
        "\n",
        "# ==== Helpers ====\n",
        "\n",
        "def parse_index(index_path: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Returns list of (path, label_str).\n",
        "    Supports:\n",
        "      * CSV with header path,label\n",
        "      * TXT lines: \"path label\" or \"path,label\"; path may contain spaces\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    if index_path.lower().endswith(\".csv\"):\n",
        "        with open(index_path, newline=\"\") as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            assert \"path\" in reader.fieldnames, \"CSV must have 'path' column\"\n",
        "            for row in reader:\n",
        "                p = row[\"path\"].strip()\n",
        "                lab = (row.get(\"label\") or row.get(\"labels\") or \"\").strip()\n",
        "                items.append((p, lab))\n",
        "    if ROOT_DIR:\n",
        "        items = [(os.path.join(ROOT_DIR, p), lab) for p, lab in items]\n",
        "    return items\n",
        "\n",
        "def check_one(path: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Try opening the image safely. Return a dict with status and details.\n",
        "    \"\"\"\n",
        "    info = {\n",
        "        \"path\": path,\n",
        "        \"exists\": os.path.exists(path),\n",
        "        \"ok\": False,\n",
        "        \"err\": None,\n",
        "        \"err_type\": None,\n",
        "        \"size\": None,\n",
        "        \"mode\": None,\n",
        "        \"size_ok\": None,\n",
        "    }\n",
        "    if not info[\"exists\"]:\n",
        "        info[\"err\"] = \"File not found\"\n",
        "        info[\"err_type\"] = \"NotFound\"\n",
        "        return info\n",
        "    try:\n",
        "        # First pass: verify header without decoding full image\n",
        "        with Image.open(path) as im:\n",
        "            im.verify()\n",
        "        # Second pass: actually load to catch truncated data\n",
        "        with Image.open(path) as im:\n",
        "            im.load()\n",
        "            w, h = im.size\n",
        "            info[\"size\"] = (w, h)\n",
        "            info[\"mode\"] = im.mode\n",
        "            info[\"size_ok\"] = (w == EXPECTED_W and h == EXPECTED_H)\n",
        "        info[\"ok\"] = True\n",
        "        return info\n",
        "    except UnidentifiedImageError as e:\n",
        "        info[\"err\"] = str(e)\n",
        "        info[\"err_type\"] = \"UnidentifiedImageError\"\n",
        "    except OSError as e:\n",
        "        info[\"err\"] = str(e)\n",
        "        info[\"err_type\"] = \"OSError\"\n",
        "    except Exception as e:\n",
        "        info[\"err\"] = str(e)\n",
        "        info[\"err_type\"] = e.__class__.__name__\n",
        "    return info\n",
        "\n",
        "# ==== Run ====\n",
        "items = parse_index(INDEX_PATH)\n",
        "paths = [p for p, _ in items]\n",
        "print(f\"Indexed items: {len(items)}\")\n",
        "\n",
        "for group_label in set([lab for _, lab in items]):\n",
        "    print(f\"Group {group_label}: {len([p for p, lab in items if lab == group_label])}\")\n",
        "\n",
        "t0 = time.time()\n",
        "results = []\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futs = [ex.submit(check_one, p) for p in paths]\n",
        "    for fut in as_completed(futs):\n",
        "        results.append(fut.result())\n",
        "dt = time.time() - t0\n",
        "print(f\"Checked {len(results)} files in {dt:.1f}s with {MAX_WORKERS} workers\")\n",
        "\n",
        "# ==== Summary ====\n",
        "missing   = [r for r in results if not r[\"exists\"]]\n",
        "bad_read  = [r for r in results if r[\"exists\"] and not r[\"ok\"]]\n",
        "wrong_sz  = [r for r in results if r[\"ok\"] and r[\"size_ok\"] is False]\n",
        "ok_files  = [r for r in results if r[\"ok\"] and r[\"size_ok\"] is True]\n",
        "\n",
        "modes = Counter([r[\"mode\"] for r in results if r[\"mode\"]])\n",
        "err_types = Counter([r[\"err_type\"] for r in bad_read])\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(f\"OK (readable & {EXPECTED_W}x{EXPECTED_H}): {len(ok_files)}\")\n",
        "print(f\"MISSING: {len(missing)}\")\n",
        "print(f\"READ ERRORS: {len(bad_read)}  (by type: {dict(err_types)})\")\n",
        "print(f\"WRONG SIZE: {len(wrong_sz)}\")\n",
        "print(f\"Image modes (for OK/loaded files): {dict(modes)}\")\n",
        "\n",
        "if missing:\n",
        "    print(f\"\\nMissing files (first {LIST_EXAMPLES}):\")\n",
        "    for r in missing[:LIST_EXAMPLES]:\n",
        "        print(\"  \", r[\"path\"])\n",
        "\n",
        "if bad_read:\n",
        "    print(f\"\\nUnreadable / corrupted (first {LIST_EXAMPLES}):\")\n",
        "    for r in bad_read[:LIST_EXAMPLES]:\n",
        "        print(f\"  {r['path']}  →  {r['err_type']}: {r['err']}\")\n",
        "\n",
        "if wrong_sz:\n",
        "    print(f\"\\nWrong size (first {LIST_EXAMPLES}):\")\n",
        "    for r in wrong_sz[:LIST_EXAMPLES]:\n",
        "        print(f\"  {r['path']}  →  got {r['size']}, expected ({EXPECTED_W}, {EXPECTED_H})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJohH3TJybSP",
        "outputId": "97b1eda6-8d87-4106-e926-0dde2d067093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed items: 21392\n",
            "Group 1: 4900\n",
            "Group 7: 1904\n",
            "Group 3: 4662\n",
            "Group 4: 3500\n",
            "Group 6: 2296\n",
            "Group 2: 2282\n",
            "Group 5: 1848\n",
            "Checked 21392 files in 13.3s with 2 workers\n",
            "\n",
            "=== SUMMARY ===\n",
            "OK (readable & 227x227): 21392\n",
            "MISSING: 0\n",
            "READ ERRORS: 0  (by type: {})\n",
            "WRONG SIZE: 0\n",
            "Image modes (for OK/loaded files): {'L': 21392}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Аугментация"
      ],
      "metadata": {
        "id": "B4o6ggNTsgUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import os, csv, sys, time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Tuple, Dict\n",
        "import tqdm\n",
        "\n",
        "INDEX_PATH   = \"/content/hirise-map-proj-v3/dataset.csv\"  # or dataset.csv\n",
        "ROOT_DIR     = \"/content/hirise-map-proj-v3/map-proj-v3/\" # optional prefix for relative paths (\"\" = leave as-is)\n",
        "EXPECTED_W   = 227\n",
        "EXPECTED_H   = 227\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def add_noise(img):\n",
        "    row , col = img.shape\n",
        "    number_of_pixels = random.randint(300, 800)\n",
        "    for i in range(number_of_pixels):\n",
        "\n",
        "        # Pick a random y coordinate\n",
        "        y_coord=random.randint(0, row - 1)\n",
        "\n",
        "        # Pick a random x coordinate\n",
        "        x_coord=random.randint(0, col - 1)\n",
        "\n",
        "        # Color that pixel to white\n",
        "        img[y_coord][x_coord] = 255\n",
        "\n",
        "    # Randomly pick some pixels in\n",
        "    # the image for coloring them black\n",
        "    number_of_pixels = random.randint(300 , 800)\n",
        "    for i in range(number_of_pixels):\n",
        "\n",
        "        # Pick a random y coordinate\n",
        "        y_coord=random.randint(0, row - 1)\n",
        "\n",
        "        # Pick a random x coordinate\n",
        "        x_coord=random.randint(0, col - 1)\n",
        "\n",
        "        # Color that pixel to black\n",
        "        img[y_coord][x_coord] = 0\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "groups_of_images = {}\n",
        "\n",
        "with open(INDEX_PATH, \"r\") as f:\n",
        "    for line in f.readlines()[1:]:\n",
        "        parts = line.strip().split(',')\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        path, label = parts[0], parts[1]\n",
        "        if label not in groups_of_images:\n",
        "            groups_of_images[label] = []\n",
        "        groups_of_images[label].append(path)\n",
        "\n",
        "indexed_groups_of_images = {}\n",
        "\n",
        "for group_label in groups_of_images.keys():\n",
        "    print(group_label, len(groups_of_images[group_label]))\n",
        "    indexed_groups_of_images[group_label] = len(groups_of_images[group_label])\n",
        "\n",
        "indexed_groups_of_images = sorted(indexed_groups_of_images.items(), key=lambda x: x[1])\n",
        "\n",
        "print(indexed_groups_of_images)\n",
        "\n",
        "print(\"Возьму в аугментацию группу\", indexed_groups_of_images[0][0], indexed_groups_of_images[0][1])\n",
        "\n",
        "\n",
        "for group_label, group_size in enumerate(indexed_groups_of_images):\n",
        "    if group_label not in [2, 3, 4, 5, 6, 7]:\n",
        "        continue\n",
        "\n",
        "    for image in tqdm.tqdm(groups_of_images[str(group_label)]):\n",
        "        img = cv2.imread(os.path.join(ROOT_DIR, image), cv2.IMREAD_GRAYSCALE)\n",
        "        noisy_img = add_noise(img)\n",
        "        new_name = os.path.join(ROOT_DIR, image.split(\".\")[0] + str(random.randint(1, 10000)) + \"NOISE.png\")\n",
        "        cv2.imwrite(new_name, noisy_img)\n",
        "        with open(INDEX_PATH, \"a\") as f:\n",
        "            f.write(f\"\\n{new_name},{group_label}\")\n",
        "    print(f\"#{group_label} аугментирован\")\n",
        "\n",
        "\n",
        "print(\"Аугментация завершена\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEtHjop7sfwO",
        "outputId": "699f8797-d89c-46fc-c2d3-4274aa658935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 61054\n",
            "5 924\n",
            "1 4900\n",
            "3 2331\n",
            "2 1141\n",
            "6 1148\n",
            "7 952\n",
            "4 1750\n",
            "[('5', 924), ('7', 952), ('2', 1141), ('6', 1148), ('4', 1750), ('3', 2331), ('1', 4900), ('0', 61054)]\n",
            "Возьму в аугментацию группу 5 924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1141/1141 [00:02<00:00, 410.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#2 аугментирован\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2331/2331 [00:07<00:00, 326.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#3 аугментирован\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1750/1750 [00:04<00:00, 399.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#4 аугментирован\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 924/924 [00:02<00:00, 339.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#5 аугментирован\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1148/1148 [00:04<00:00, 273.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#6 аугментирован\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 952/952 [00:02<00:00, 370.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#7 аугментирован\n",
            "Аугментация завершена\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нейронка на базе Resnet50 и с батчам в 128\n",
        "тут нужно реализовать WeightedRandomSampler и взвешенный CrossEntropyLoss\n",
        "\n",
        "\n",
        "```python\n",
        "from collections import Counter\n",
        "counts = Counter(y_train)                     # по train\n",
        "w_class = {c: 1.0/max(counts[c],1) for c in range(8)}\n",
        "w_sample = [w_class[c] for c in y_train]\n",
        "sampler = torch.utils.data.WeightedRandomSampler(w_sample, num_samples=len(w_sample), replacement=True)\n",
        "\n",
        "# DataLoader(train_dataset, sampler=sampler, shuffle=False, ...)\n",
        "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([w_class[c] for c in range(8)], device=device), label_smoothing=0.05)\n",
        "\n",
        "```\n",
        "\n",
        "# Или же, убрать 0 класс\n",
        "и если никакой из нейроновов не достиг больше половины, то помечать как undefined\n",
        "\n"
      ],
      "metadata": {
        "id": "A7WD0G7X-J5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# убираем 0 класс из csv\n",
        "\n",
        "INDEX_PATH = \"/content/hirise-map-proj-v3/dataset.csv\"\n",
        "NEW_INDEX_PATH = \"/content/hirise-map-proj-v3/cleared_dataset.csv\"\n",
        "\n",
        "items = []\n",
        "with open(INDEX_PATH, newline=\"\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        p = row[\"path\"].strip()\n",
        "        lab = int(row[\"label\"]) if \"label\" in row else int(row[\"labels\"])\n",
        "        items.append((p, lab))\n",
        "\n",
        "with open(NEW_INDEX_PATH, \"w\") as f:\n",
        "    f.write(\"path,label\\n\")\n",
        "    for item in items:\n",
        "        if int(item[1]) == 0:\n",
        "            continue\n",
        "        f.write(f\"{item[0]},{item[1]}\\n\")\n"
      ],
      "metadata": {
        "id": "gZ4HGXRa_88N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wCMlLEnBwsR",
        "outputId": "1b230ceb-d3df-47f5-8ea8-a19ca0736706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, time, math, random\n",
        "from typing import List, Tuple, Dict\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "INDEX_PATH   = \"/content/hirise-map-proj-v3/cleared_dataset.csv\"  # CSV \"path,label\"\n",
        "ROOT_DIR     = \"/content/hirise-map-proj-v3/map-proj-v3/\" # optional prefix added to each path (\"\" keeps as-is)\n",
        "SAVE_DIR     = \"/content/drive/MyDrive/mars_runs\"  # where to save checkpoints/reports\n",
        "IMG_SIZE     = 227\n",
        "BATCH_SIZE   = 128\n",
        "NUM_WORKERS  = 4                   # 2-4 is fine on Colab\n",
        "PATIENCE     = 5                   # early stopping patience (epochs)\n",
        "SEED         = 42\n",
        "\n",
        "# Stage 1 (linear probe)\n",
        "WARMUP_EPOCHS = 3                  # train only final layer\n",
        "LR_FC         = 6e-3               # замораживаем голову, чекаем на что способен бекбон\n",
        "\n",
        "# Stage 2 (full fine-tune)\n",
        "FT_EPOCHS     = 50                 # max; early stopping will cut earlier\n",
        "LR_FT         = 4e-4               # чуть меняем бекбон под задач\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "LABEL_SMOOTH  = 0.05               # small smoothing helps noisy labels\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "BCCWB6wU-XHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "# если не CUDA, то ИДИ И МЕНЯЙ НА T4 ИНАЧЕ УБЬЕЕЕЕТ!!!!!"
      ],
      "metadata": {
        "id": "JgSGclCL-u1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2e27a5-3065-4851-e11a-155eb77814b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ––––––––––––––\n",
        "# Functions\n",
        "# ––––––––––––––\n",
        "def parse_index(index_path: str) -> List[Tuple[str, int]]:\n",
        "    items = []\n",
        "    with open(index_path, newline=\"\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            p = row[\"path\"].strip()\n",
        "            lab = int(row[\"label\"]) if \"label\" in row else int(row[\"labels\"])\n",
        "            items.append((p, lab))\n",
        "    if ROOT_DIR:\n",
        "        items = [(os.path.join(ROOT_DIR, p), lab) for p, lab in items]\n",
        "    return items\n",
        "\n",
        "def subset(indices, data):\n",
        "    return [data[i] for i in indices]"
      ],
      "metadata": {
        "id": "2Hk3DE_h_vlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Index parsing (TXT or CSV)\n",
        "# -----------------------\n",
        "\n",
        "raw_items = parse_index(INDEX_PATH)\n",
        "print(\"Indexed:\", len(raw_items))\n",
        "\n",
        "# Map original numeric labels -> contiguous [0..K-1]\n",
        "orig_labels = sorted({lab for _, lab in raw_items})\n",
        "orig2idx = {lab:i for i, lab in enumerate(orig_labels)}\n",
        "idx2orig = {i:lab for lab,i in orig2idx.items()}\n",
        "data = [(p, orig2idx[lab]) for p, lab in raw_items]\n",
        "classes = [str(ol) for ol in orig_labels]\n",
        "num_classes = len(classes)\n",
        "print(\"Num classes:\", num_classes)\n",
        "print(\"Original label → index mapping:\", orig2idx)\n"
      ],
      "metadata": {
        "id": "Zsu0fTaKA0g-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bad3af8-11cd-42e8-8a68-a00e5449403d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed: 21392\n",
            "Num classes: 7\n",
            "Original label → index mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Train/Val/Test split (stratified 80/10/10)\n",
        "# -----------------------\n",
        "y = [lab for _, lab in data]\n",
        "idx_all = np.arange(len(data))\n",
        "idx_train, idx_test = train_test_split(idx_all, test_size=0.10, random_state=SEED, stratify=y)\n",
        "y_train_tmp = [y[i] for i in idx_train]\n",
        "idx_train, idx_val = train_test_split(idx_train, test_size=1/9, random_state=SEED, stratify=y_train_tmp)\n",
        "\n",
        "\n",
        "train_items = subset(idx_train, data)\n",
        "val_items   = subset(idx_val, data)\n",
        "test_items  = subset(idx_test, data)\n",
        "print(f\"Splits -> train={len(train_items)}  val={len(val_items)}  test={len(test_items)}\")\n"
      ],
      "metadata": {
        "id": "BwQR1H-iA4Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de95a671-d91c-4b2f-eafd-35b130571242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits -> train=17112  val=2140  test=2140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Dataset / Transforms\n",
        "# -----------------------\n",
        "class MarsDataset(Dataset):\n",
        "    \"\"\"Single-label dataset; converts grayscale/rgba to RGB silently.\"\"\"\n",
        "    def __init__(self, items, transform):\n",
        "        self.items = items\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        p, lab = self.items[i]\n",
        "        img = Image.open(p)\n",
        "        if img.mode != \"RGB\":\n",
        "            # unify to 3 channels\n",
        "            if img.mode in (\"L\", \"I;16\"):\n",
        "                img = img.convert(\"L\")\n",
        "                img = Image.merge(\"RGB\", (img, img, img))\n",
        "            else:\n",
        "                img = img.convert(\"RGB\")\n",
        "        x = self.transform(img)\n",
        "        return x, torch.tensor(lab, dtype=torch.long)\n",
        "\n",
        "norm = transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                            std=[0.229,0.224,0.225])\n",
        "\n",
        "base_tfms = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    norm,\n",
        "])\n",
        "\n",
        "train_ds = MarsDataset(train_items, base_tfms)\n",
        "val_ds   = MarsDataset(val_items,   base_tfms)\n",
        "test_ds  = MarsDataset(test_items,  base_tfms)\n",
        "\n",
        "# Calculate weights for WeightedRandomSampler\n",
        "y_train = [lab for _, lab in train_items]\n",
        "counts = Counter(y_train)\n",
        "w_class = {c: 1.0/max(counts[c],1) for c in range(num_classes)}\n",
        "w_sample = [w_class[c] for c in y_train]\n",
        "sampler = torch.utils.data.WeightedRandomSampler(w_sample, num_samples=len(w_sample), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS,\n",
        "    pin_memory=True, persistent_workers=(NUM_WORKERS>0), prefetch_factor=2)\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
        "    pin_memory=True, persistent_workers=(NUM_WORKERS>0), prefetch_factor=2)\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
        "    pin_memory=True, persistent_workers=(NUM_WORKERS>0), prefetch_factor=2)"
      ],
      "metadata": {
        "id": "0I0WOP6BBdud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41b64ce-03bf-49a0-86d6-2b0ba3760e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Losses/optim\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
        "\n",
        "\n",
        "optimizer_fc = torch.optim.AdamW(model.fc.parameters(), lr=LR_FC, weight_decay=WEIGHT_DECAY)\n",
        "optimizer_ft = torch.optim.AdamW(model.parameters(),   lr=LR_FT, weight_decay=WEIGHT_DECAY)\n",
        "scheduler_ft = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=FT_EPOCHS)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y) # Use the single criterion\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.append(preds.detach().cpu().numpy())\n",
        "            all_targets.append(y.detach().cpu().numpy())\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    y_pred = np.concatenate(all_preds)\n",
        "    y_true = np.concatenate(all_targets)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    return avg_loss, f1, y_true, y_pred\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_path = os.path.join(SAVE_DIR, \"best.pt\")\n",
        "log_rows = []\n",
        "\n",
        "# -----------------------\n",
        "# Stage 1: Linear probe (fc only)\n",
        "# -----------------------\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "print(\"\\n=== Stage 1: linear probe ===\")\n",
        "for epoch in range(1, WARMUP_EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        optimizer_fc.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y) # Use the single criterion\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_fc)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        n += x.size(0)\n",
        "    tr_loss = total_loss / n\n",
        "    val_loss, val_f1, _, _ = evaluate(val_loader)\n",
        "    log_rows.append((\"stage1\", epoch, tr_loss, val_loss, val_f1))\n",
        "    print(f\"[S1 {epoch:02d}] train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} val_F1={val_f1:.4f}\")\n",
        "    # save if best\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save({\"model\": model.state_dict(),\n",
        "                    \"classes\": classes,\n",
        "                    \"img_size\": IMG_SIZE,\n",
        "                    \"idx2orig\": idx2orig}, best_path)\n",
        "        print(f\"  → New best (F1={best_f1:.4f}) saved to {best_path}\")\n",
        "\n",
        "# -----------------------\n",
        "# Stage 2: Full fine-tune\n",
        "# -----------------------\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "print(\"\\n=== Stage 2: full fine-tune ===\")\n",
        "pat = PATIENCE\n",
        "for epoch in range(1, FT_EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        optimizer_ft.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y) # Use the single criterion\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_ft)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        n += x.size(0)\n",
        "    scheduler_ft.step()\n",
        "    tr_loss = total_loss / n\n",
        "    val_loss, val_f1, _, _ = evaluate(val_loader)\n",
        "    log_rows.append((\"stage2\", epoch, tr_loss, val_loss, val_f1))\n",
        "    print(f\"[S2 {epoch:02d}] train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} val_F1={val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        pat = PATIENCE\n",
        "        torch.save({\"model\": model.state_dict(),\n",
        "                    \"classes\": classes,\n",
        "                    \"img_size\": IMG_SIZE,\n",
        "                    \"idx2orig\": idx2orig}, best_path)\n",
        "        print(f\"  → New best (F1={best_f1:.4f}) saved to {best_path}\")\n",
        "    else:\n",
        "        pat -= 1\n",
        "        if pat <= 0:\n",
        "            print(\"  → Early stopping.\")\n",
        "            break\n",
        "\n",
        "# Save training log\n",
        "log_df = pd.DataFrame(log_rows, columns=[\"stage\",\"epoch\",\"train_loss\",\"val_loss\",\"val_f1\"])\n",
        "log_csv = os.path.join(SAVE_DIR, \"train_log.csv\")\n",
        "log_df.to_csv(log_csv, index=False)\n",
        "print(\"Log saved to:\", log_csv)\n",
        "\n",
        "# -----------------------\n",
        "# Test evaluation (best checkpoint)\n",
        "# -----------------------\n",
        "ckpt = torch.load(best_path, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "test_loss, test_f1, y_true, y_pred = evaluate(test_loader)\n",
        "print(f\"\\nTEST: loss={test_loss:.4f}  macro-F1={test_f1:.4f}\")\n",
        "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
        "cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "cm_csv = os.path.join(SAVE_DIR, \"confusion_matrix.csv\")\n",
        "cm_df.to_csv(cm_csv)\n",
        "print(\"Confusion matrix saved to:\", cm_csv)\n",
        "\n",
        "print(\"\\nBest model:\", best_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pC0CgLw12kO",
        "outputId": "3aa18b99-39f3-4126-ba68-d45a43778f00",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Stage 1: linear probe ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
            "/tmp/ipython-input-894261447.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S1 01] train_loss=0.6306 | val_loss=0.4818 val_F1=0.9251\n",
            "  → New best (F1=0.9251) saved to /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S1 02] train_loss=0.4446 | val_loss=0.4386 val_F1=0.9459\n",
            "  → New best (F1=0.9459) saved to /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S1 03] train_loss=0.4168 | val_loss=0.4249 val_F1=0.9519\n",
            "  → New best (F1=0.9519) saved to /content/drive/MyDrive/mars_runs/best.pt\n",
            "\n",
            "=== Stage 2: full fine-tune ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 01] train_loss=0.3301 | val_loss=0.2943 val_F1=0.9926\n",
            "  → New best (F1=0.9926) saved to /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 02] train_loss=0.2690 | val_loss=0.2730 val_F1=0.9957\n",
            "  → New best (F1=0.9957) saved to /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 03] train_loss=0.2643 | val_loss=0.2851 val_F1=0.9899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 04] train_loss=0.2596 | val_loss=0.2636 val_F1=0.9986\n",
            "  → New best (F1=0.9986) saved to /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 05] train_loss=0.2615 | val_loss=0.3046 val_F1=0.9832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 06] train_loss=0.2662 | val_loss=0.2750 val_F1=0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 07] train_loss=0.2605 | val_loss=0.3079 val_F1=0.9895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 08] train_loss=0.2626 | val_loss=0.2709 val_F1=0.9964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-894261447.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 09] train_loss=0.2585 | val_loss=0.3191 val_F1=0.9683\n",
            "  → Early stopping.\n",
            "Log saved to: /content/drive/MyDrive/mars_runs/train_log.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-894261447.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST: loss=0.2623  macro-F1=0.9976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    0.9980    0.9990       490\n",
            "           2     0.9912    0.9912    0.9912       228\n",
            "           3     0.9957    0.9957    0.9957       466\n",
            "           4     1.0000    1.0000    1.0000       350\n",
            "           5     1.0000    1.0000    1.0000       185\n",
            "           6     1.0000    1.0000    1.0000       230\n",
            "           7     0.9948    1.0000    0.9974       191\n",
            "\n",
            "    accuracy                         0.9977      2140\n",
            "   macro avg     0.9974    0.9978    0.9976      2140\n",
            "weighted avg     0.9977    0.9977    0.9977      2140\n",
            "\n",
            "Confusion matrix saved to: /content/drive/MyDrive/mars_runs/confusion_matrix.csv\n",
            "\n",
            "Best model: /content/drive/MyDrive/mars_runs/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQgvIXdf_5sw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}